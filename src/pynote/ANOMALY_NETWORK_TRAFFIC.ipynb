{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakhin03/PROJECT_ASnED_HUST/blob/main/src/pynote/ANOMALY_NETWORK_TRAFFIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROJECT - ANORMARL NETWORK TRAFFIC DETECTION \n",
        "\n",
        "## Goals:\n",
        "  * Detecting ANORMARL NETWORK TRAFFIC\n",
        "\n",
        "## Folder structure:\n",
        "```\n",
        ".\n",
        "├── Datasets\n",
        "│   └── ...\n",
        "├── Figure\n",
        "│   └── ...\n",
        "├── README.md\n",
        "├── requirements.txt\n",
        "└── src\n",
        "    ├── app.py\n",
        "    └── pynote\n",
        "        └── ANOMALY_NETWORK_TRAFFIC.ipynb\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZA3lnVR-zc7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage:"
      ],
      "metadata": {
        "id": "Wq8NTQulE_c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/jakhin03/PROJECT_ASnED_HUST\""
      ],
      "metadata": {
        "id": "aKt83fYtE2No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PROJECT_ASnED_HUST"
      ],
      "metadata": {
        "id": "iiEqSblqKlR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "eZoTu2MpFM48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd src/pynote"
      ],
      "metadata": {
        "id": "8PtxUA6mFE3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import module and library"
      ],
      "metadata": {
        "id": "T42qWdI35szA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.datasets import load_files\n",
        "from pyvi import ViTokenizer\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0Fl_ckwR2LSx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocessing and data exploration:\n",
        "\n"
      ],
      "metadata": {
        "id": "T4vEstjs3cDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Datasets can find on: [source](https://archive.ics.uci.edu/ml/machine-learning-databases/kddcup99-mld/kddcup99.html)"
      ],
      "metadata": {
        "id": "hCq0Rk_dKKpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"../../Datasets/network_data.csv\")\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "data.head()\n",
        "print('Number of days for which data is available {:d}'.format(data['date'].nunique()))\n",
        "print('Unique local ip {:d}'.format(data['l_ipn'].nunique()))\n",
        "print('Unique remote ASN {:d}'.format(data['r_asn'].nunique()))\n",
        "print('Minimum flow count per day {:d}'.format(data['f'].min()))\n",
        "print('Maximum flow count per day {:d}'.format(data['f'].max()))\n",
        "print(data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "cpedLGcfziCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Exploring datasets:\n",
        "* Create dataframe for visualization"
      ],
      "metadata": {
        "id": "fpIIy77tHZU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {'2006-08-24':1,'2006-09-04':5,'2006-09-18':4,'2006-09-26':3,'2006-09-26':6}\n",
        "marked_anomalies = pd.DataFrame.from_dict(dic,orient='index')\n",
        "marked_anomalies.reset_index(inplace = True)\n",
        "marked_anomalies.columns = ['date','l_ipn']\n",
        "print(marked_anomalies)"
      ],
      "metadata": {
        "id": "dGBRThQMHqLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Aggregating daily connections"
      ],
      "metadata": {
        "id": "jmHOluCSHwvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_aggregate = data.groupby(['date'])[['f']].sum()\n",
        "daily_aggregate.reset_index(inplace = True)\n",
        "daily_aggregate[['f']].describe()"
      ],
      "metadata": {
        "id": "xpT8jQnkH26Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_mean = round(daily_aggregate['f'].mean(),2)\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(data['date'],data['f'])\n",
        "[plt.axvline(x=_x, color='r' , label = 'Recorded Anomoly {}'.format(ip)) for _x,ip in list(marked_anomalies[['date','l_ipn']].to_records(index=False))]\n",
        "plt.axhline(y= daily_mean, color='g', label = 'Mean Connections')\n",
        "plt.plot(data['date'],data['f'].rolling(7).mean(), label = '7 days Rolling average')\n",
        "plt.xticks(data['date'][::2],  rotation='vertical')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('Connection')\n",
        "plt.title('Daily Aggregate Connections')\n",
        "plt.fill_between(data['date'],data['f'],color='aqua')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "rxbuJSLrEL7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_aggregate_l_ipn = data.groupby(['l_ipn','date'])[['f']].sum()\n",
        "daily_aggregate_l_ipn.reset_index(inplace= True)"
      ],
      "metadata": {
        "id": "LgFFVm6tJwU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(20, 15))\n",
        "\n",
        "plot_row = 0\n",
        "plot_col = 0\n",
        "\n",
        "for i in range(data['l_ipn'].nunique()):\n",
        "    temp = daily_aggregate_l_ipn[daily_aggregate_l_ipn['l_ipn'] == i]\n",
        "    axes[plot_row,plot_col].set_title(i)\n",
        "    axes[plot_row,plot_col].set_xlabel('date')\n",
        "    axes[plot_row,plot_col].set_ylabel('connections')\n",
        "    \n",
        "    axes[plot_row,plot_col].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "    \n",
        "    axes[plot_row,plot_col].plot(temp['date'],temp['f'], color = 'salmon')\n",
        "    axes[plot_row,plot_col].get_xaxis().set_visible(False)\n",
        "    axes[plot_row,plot_col].fill_between(temp['date'],temp['f'], color='peachpuff')\n",
        "    \n",
        "\n",
        "    plot_col = plot_col + 1\n",
        "    if(plot_col == 2):\n",
        "        plot_row = plot_row + 1\n",
        "        plot_col = 0\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-2bnSv3YIMYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Aggregating flows on per r_asn"
      ],
      "metadata": {
        "id": "cVfsx6vPJ5FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_aggregate_r_asn = data.groupby(['r_asn'])[['f']].sum()\n",
        "daily_aggregate_r_asn.reset_index(inplace = True)"
      ],
      "metadata": {
        "id": "pM6lGf2VJ96w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "daily_aggregate_r_asn['f'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tJGjBg8J_ny",
        "outputId": "1a8ec650-9e7a-44f6-a629-a0e6cbcd3804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      2005.00\n",
              "mean        974.41\n",
              "std       23862.63\n",
              "min           1.00\n",
              "25%           2.00\n",
              "50%           8.00\n",
              "75%          43.00\n",
              "max     1059254.00\n",
              "Name: f, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(i)\n",
        "plt.xlabel('r_asn')\n",
        "plt.ylabel('connections')\n",
        "plt.xticks(rotation='vertical')\n",
        "#n_bins =  daily_aggregate_r_asn['r_asn']\n",
        "#plt.hist(daily_aggregate_r_asn['f'], n_bins, histtype ='bar')\n",
        "plt.plot(daily_aggregate_r_asn['r_asn'],daily_aggregate_r_asn['f'], color = 'salmon')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YdaWhnnYKBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Anomaly detection\n",
        "*Anomalies are marked in red dot in graph*"
      ],
      "metadata": {
        "id": "0SNM3rm_KShv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Using prophet library"
      ],
      "metadata": {
        "id": "F6yuJDTdLAlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prophet"
      ],
      "metadata": {
        "id": "uuqmo_njggkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import to_datetime\n",
        "from prophet import Prophet"
      ],
      "metadata": {
        "id": "X1E0RE4mLxzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_daily_aggregate_l_ipn(in_l_ipn):\n",
        "    temp_data = daily_aggregate_l_ipn[daily_aggregate_l_ipn['l_ipn'] == in_l_ipn].drop(['l_ipn'],axis = 1)\n",
        "    temp_data.columns = ['ds','y']\n",
        "    temp_data['ds'] = to_datetime(temp_data['ds'])\n",
        "    temp_data.reset_index(inplace=True,drop=True)\n",
        "    return temp_data"
      ],
      "metadata": {
        "id": "k_OlKj7IKXjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_forecast(ts,in_l_ipn):\n",
        "    \n",
        "    model = Prophet(seasonality_mode='additive',daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = True)\n",
        "    model.fit(ts)\n",
        "    forecast = model.predict(pd.DataFrame(ts['ds']))\n",
        "    \n",
        "    ts['anomaly'] = 0\n",
        "    p_color = np.full((ts.shape[0],1),'green')\n",
        "    for i in range(forecast.shape[0]):\n",
        "        if((forecast.at[i,'yhat_lower'] > ts.at[i,'y']) or (forecast.at[i,'yhat_upper'] < ts.at[i,'y'])):\n",
        "            ts.at[i,'anomaly'] = 1\n",
        "            p_color[i] = 'red'\n",
        "                \n",
        "    model.plot(forecast)\n",
        "    \n",
        "    plt.scatter(ts['ds'],ts['y'],c=p_color.ravel())\n",
        "    plt.title('Forcast plot for l_ipn %d' %in_l_ipn)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0Hzhn0ZiKwhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(data['l_ipn'].nunique()):\n",
        "    get_forecast(get_daily_aggregate_l_ipn(i),i)"
      ],
      "metadata": {
        "id": "b9Klhi5nKztK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Using luminol:"
      ],
      "metadata": {
        "id": "7t70C-Qskqie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install luminol"
      ],
      "metadata": {
        "id": "rzLvtbYhk3wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import luminol\n",
        "from luminol.anomaly_detector import AnomalyDetector"
      ],
      "metadata": {
        "id": "QrKHErtqlCax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_luminol_anomalies(in_df):\n",
        "    in_df['isAnomaly'] = 0\n",
        "    detector = AnomalyDetector(in_df['y'].to_dict())\n",
        "    anomalies = detector.get_anomalies()\n",
        "    time_period = ()\n",
        "    for j in range(len(anomalies)):\n",
        "        time_period = anomalies[j].get_time_window()\n",
        "        for k in time_period:\n",
        "            in_df.at[k,'isAnomaly'] = 1     \n",
        "    return(in_df)    "
      ],
      "metadata": {
        "id": "SFVQCfO2lESA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(data['l_ipn'].nunique()):\n",
        "    t_df = get_luminol_anomalies(get_daily_aggregate_l_ipn(i))\n",
        "    \n",
        "    colors = {0:'green', 1:'red'}\n",
        "   \n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(t_df['ds'],t_df['y'])\n",
        "    plt.scatter(t_df['ds'],t_df['y'],c=t_df['isAnomaly'].apply(lambda x: colors[x]))\n",
        "    plt.title('Forcast plot for l_ipn %d' %i)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oe47bm3ZlFl6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}